"""
Simple Validation for UV-Vis PINN Implementation
===============================================

This script validates the core functionality of the UV-Vis PINN implementation
without requiring DeepXDE or TensorFlow dependencies.

"""

import numpy as np
import sys
import logging
from pathlib import Path
import traceback

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_data_preprocessing():
    """Test data preprocessing functionality."""
    logger.info("Testing Phase 1: Data Preprocessing...")
    
    try:
        from data_preprocessing import UVVisDataProcessor, load_uvvis_data
        
        # Test with real data
        csv_path = "/Users/aditya/CodingProjects/datasets/0.30MB_AuNP_As.csv"
        
        if not Path(csv_path).exists():
            logger.error(f"CSV file not found: {csv_path}")
            return False
        
        # Test basic loading
        processor = UVVisDataProcessor(csv_path)
        processor.load_and_validate_data()
        logger.info("✓ Data loading successful")
        
        # Test spectral extraction
        wavelengths, concentrations, absorbance_matrix = processor.extract_spectral_components()
        logger.info(f"✓ Extracted {len(wavelengths)} wavelengths, {len(concentrations)} concentrations")
        
        # Test Beer-Lambert processing
        baseline, differential = processor.compute_beer_lambert_components()
        logger.info(f"✓ Beer-Lambert components: baseline shape {baseline.shape}, differential shape {differential.shape}")
        
        # Test normalization
        normalized_data = processor.normalize_inputs()
        logger.info("✓ Input normalization successful")
        
        # Test training data creation
        X_train, y_train = processor.create_training_data()
        logger.info(f"✓ Training data created: X={X_train.shape}, y={y_train.shape}")
        
        # Validate data quality
        assert len(wavelengths) == 601, f"Expected 601 wavelengths, got {len(wavelengths)}"
        assert len(concentrations) == 6, f"Expected 6 concentrations, got {len(concentrations)}"
        assert X_train.shape[1] == 2, f"Expected 2 input features, got {X_train.shape[1]}"
        assert y_train.shape[1] == 1, f"Expected 1 output feature, got {y_train.shape[1]}"
        
        logger.info("Phase 1 validation PASSED")
        return True
        
    except Exception as e:
        logger.error(f"Phase 1 validation FAILED: {e}")
        logger.error(traceback.format_exc())
        return False

def test_model_definition():
    """Test model definition functionality (without DeepXDE)."""
    logger.info("Testing Phase 2: Model Definition...")
    
    try:
        # Import without triggering DeepXDE initialization
        import importlib.util
        spec = importlib.util.spec_from_file_location("model_definition", "model_definition.py")
        model_module = importlib.util.module_from_spec(spec)
        
        # Mock DeepXDE to avoid import issues
        import sys
        from unittest.mock import Mock
        
        mock_dde = Mock()
        mock_dde.geometry.Rectangle = Mock()
        mock_dde.nn.FNN = Mock()
        mock_dde.callbacks = Mock()
        mock_dde.data.PDE = Mock()
        mock_dde.data.DataSet = Mock()
        mock_dde.data.combine.CombinedData = Mock()
        mock_dde.Model = Mock()
        mock_dde.icbc.DirichletBC = Mock()
        mock_dde.backend.concat = Mock()
        mock_dde.grad.jacobian = Mock()
        
        sys.modules['deepxde'] = mock_dde
        
        # Now import our module
        spec.loader.exec_module(model_module)
        
        # Test SpectroscopyPINN class
        SpectroscopyPINN = model_module.SpectroscopyPINN
        
        # Test initialization
        pinn = SpectroscopyPINN(
            wavelength_range=(200, 800),
            concentration_range=(0, 60),
            layer_sizes=[2, 64, 128, 128, 64, 32, 1]
        )
        
        logger.info("✓ SpectroscopyPINN initialization successful")
        
        # Test configuration validation
        assert pinn.wavelength_range == (200, 800)
        assert pinn.concentration_range == (0, 60)
        assert pinn.layer_sizes == [2, 64, 128, 128, 64, 32, 1]
        assert pinn.path_length == 1.0
        
        logger.info("✓ Model parameters validated")
        
        # Test summary generation
        summary = pinn.get_model_summary()
        
        required_sections = ['architecture', 'domain', 'physics', 'geometry']
        for section in required_sections:
            assert section in summary, f"Missing summary section: {section}"
        
        logger.info("✓ Model summary generation successful")
        
        # Test factory function
        create_spectroscopy_pinn = model_module.create_spectroscopy_pinn
        pinn_factory = create_spectroscopy_pinn(architecture="standard")
        
        assert isinstance(pinn_factory, SpectroscopyPINN)
        logger.info("✓ Factory function successful")
        
        logger.info("Phase 2 validation PASSED")
        return True
        
    except Exception as e:
        logger.error(f"Phase 2 validation FAILED: {e}")
        logger.error(traceback.format_exc())
        return False

def test_loss_functions():
    """Test loss function interfaces (without TensorFlow)."""
    logger.info("Testing Phase 3: Loss Functions...")
    
    try:
        # Try to validate the loss function module structure
        with open("loss_functions.py", 'r') as f:
            content = f.read()
        
        # Check for required classes and functions
        required_items = [
            'class UVVisLossFunction',
            'class AdaptiveLossWeighting', 
            'def create_uvvis_loss_function',
            'def validate_loss_function'
        ]
        
        for item in required_items:
            assert item in content, f"Missing required item: {item}"
        
        logger.info("✓ Loss function module structure validated")
        
        # Check for proper multi-component loss implementation
        physics_indicators = [
            'L_data',
            'L_phys', 
            'L_smooth',
            'beer_lambert',
            'physics_constraint',
            'smoothness'
        ]
        
        found_physics = sum(1 for indicator in physics_indicators if indicator in content)
        assert found_physics >= 4, f"Insufficient physics implementation indicators found: {found_physics}/6"
        
        logger.info("✓ Multi-component loss structure validated")
        
        # Check for adaptive weighting
        adaptive_indicators = ['adaptive_weighting', 'update_weights', 'adaptation_rate']
        found_adaptive = sum(1 for indicator in adaptive_indicators if indicator in content)
        assert found_adaptive >= 2, f"Insufficient adaptive weighting implementation: {found_adaptive}/3"
        
        logger.info("✓ Adaptive weighting structure validated")
        
        logger.info("Phase 3 validation PASSED (interface validation only)")
        return True
        
    except Exception as e:
        logger.error(f"Phase 3 validation FAILED: {e}")
        logger.error(traceback.format_exc())
        return False

def test_training_pipeline():
    """Test training pipeline interfaces (without DeepXDE)."""
    logger.info("Testing Phase 4: Training Pipeline...")
    
    try:
        # Validate training module structure
        with open("training.py", 'r') as f:
            content = f.read()
        
        # Check for required classes
        required_classes = [
            'class UVVisTrainingStrategy',
            'class UVVisLeaveOneScanOutCV',
            'class TrainingMetricsTracker',
            'def create_training_pipeline'
        ]
        
        for cls in required_classes:
            assert cls in content, f"Missing required class: {cls}"
        
        logger.info("✓ Training pipeline structure validated")
        
        # Check for multi-stage training
        training_indicators = [
            'initialization',
            'adam_training', 
            'lbfgs_refinement',
            'adaptive_switching',
            'convergence_patience'
        ]
        
        found_training = sum(1 for indicator in training_indicators if indicator in content)
        assert found_training >= 4, f"Insufficient multi-stage training implementation: {found_training}/5"
        
        logger.info("✓ Multi-stage training structure validated")
        
        # Check for cross-validation
        cv_indicators = [
            'leave_one_scan_out',
            'cross_validation',
            'fold',
            'held_out_concentration'
        ]
        
        found_cv = sum(1 for indicator in cv_indicators if indicator in content)
        assert found_cv >= 3, f"Insufficient cross-validation implementation: {found_cv}/4"
        
        logger.info("✓ Cross-validation structure validated")
        
        logger.info("Phase 4 validation PASSED (interface validation only)")
        return True
        
    except Exception as e:
        logger.error(f"Phase 4 validation FAILED: {e}")
        logger.error(traceback.format_exc())
        return False

def test_integration_compatibility():
    """Test integration compatibility between phases."""
    logger.info("Testing Integration Compatibility...")
    
    try:
        # Test that data preprocessing creates compatible output for model
        from data_preprocessing import UVVisDataProcessor
        
        csv_path = "/Users/aditya/CodingProjects/datasets/0.30MB_AuNP_As.csv"
        
        if not Path(csv_path).exists():
            logger.warning("CSV file not found, skipping data compatibility test")
            logger.info("Integration validation PASSED (limited)")
            return True
        
        processor = UVVisDataProcessor(csv_path)
        processor.load_and_validate_data()
        processor.extract_spectral_components()
        processor.compute_beer_lambert_components()
        
        X_train, y_train = processor.create_training_data()
        
        # Check data format compatibility
        assert X_train.shape[1] == 2, f"Model expects 2 inputs, data provides {X_train.shape[1]}"
        assert y_train.shape[1] == 1, f"Model expects 1 output, data provides {y_train.shape[1]}"
        
        logger.info("✓ Data-model format compatibility validated")
        
        # Check normalization bounds
        normalized_data = processor.normalize_inputs()
        wl_norm = normalized_data['wavelengths_norm']
        conc_norm = normalized_data['concentrations_norm']
        
        # Wavelength should be normalized to [-1, 1] range
        assert wl_norm.min() >= -1.1 and wl_norm.max() <= 1.1, f"Wavelength normalization out of bounds: [{wl_norm.min()}, {wl_norm.max()}]"
        
        # Concentration should be normalized to [0, 1] range  
        assert conc_norm.min() >= -0.1 and conc_norm.max() <= 1.1, f"Concentration normalization out of bounds: [{conc_norm.min()}, {conc_norm.max()}]"
        
        logger.info("✓ Normalization bounds validated")
        
        # Check Beer-Lambert physics consistency
        baseline, differential = processor.compute_beer_lambert_components()
        
        # Differential absorption should be reasonable
        assert np.all(np.isfinite(differential)), "Non-finite values in differential absorption"
        assert differential.shape[0] == len(processor.wavelengths), "Differential absorption wavelength dimension mismatch"
        
        logger.info("✓ Physics consistency validated")
        
        logger.info("Integration validation PASSED")
        return True
        
    except Exception as e:
        logger.error(f"Integration validation FAILED: {e}")
        logger.error(traceback.format_exc())
        return False

def main():
    """Run all validation tests."""
    print("="*60)
    print("UV-VIS PINN IMPLEMENTATION VALIDATION")
    print("="*60)
    
    results = {}
    
    # Run all tests
    results['phase_1'] = test_data_preprocessing()
    results['phase_2'] = test_model_definition()
    results['phase_3'] = test_loss_functions()
    results['phase_4'] = test_training_pipeline()
    results['integration'] = test_integration_compatibility()
    
    # Summary
    print("\n" + "="*60)
    print("VALIDATION SUMMARY")
    print("="*60)
    
    passed = sum(1 for result in results.values() if result)
    total = len(results)
    
    for phase, result in results.items():
        status = "PASSED" if result else "FAILED"
        icon = "✓" if result else "✗"
        print(f"{icon} {phase.replace('_', ' ').title()}: {status}")
    
    print("-" * 60)
    print(f"Overall: {passed}/{total} tests passed")
    
    if passed == total:
        print("✓ ALL VALIDATIONS PASSED")
        print("\nImplementation is ready for phases 3-4 integration!")
        return 0
    else:
        print("✗ SOME VALIDATIONS FAILED")
        print(f"\nPlease address the {total - passed} failed test(s) before proceeding.")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)